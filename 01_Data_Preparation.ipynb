{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation\n",
        "---\n",
        "\n",
        "This repository uses simulated orange juice sales data from [Azure Open Datasets](https://azure.microsoft.com/services/open-datasets/) to walk you through the process of training many models and forecasting on Azure Machine Learning. \n",
        "\n",
        "This notebook walks you through all the necessary steps to configure the data for this solution accelerator, including:\n",
        "\n",
        "1. Download the sample data\n",
        "2. Split in training/forecasting sets\n",
        "3. Connect to your workspace and upload the data to its Datastore\n",
        "\n",
        "### Prerequisites\n",
        "If you have already run the [00_Setup_AML_Workspace](00_Setup_AML_Workspace.ipynb) notebook you are all set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.0 Download sample data\n",
        "\n",
        "The time series data used in this example was simulated based on the University of Chicago's Dominick's Finer Foods dataset, which featured two years of sales of 3 different orange juice brands for individual stores. You can learn more about the dataset [here](https://azure.microsoft.com/services/open-datasets/catalog/sample-oj-sales-simulated/). \n",
        "\n",
        "The full dataset includes simulated sales for 3,991 stores with 3 orange juice brands each, thus allowing 11,973 models to be trained to showcase the power of the many models pattern. Each series contains data from '1990-06-14' to '1992-10-01'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You'll need the `azureml-opendatasets` package to download the data. You can install it with the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start by downloading the first 10 files but you can easily edit the code below to train all 11,973 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.0 Split data in two sets\n",
        "\n",
        "We will now split each dataset in two parts: one will be used for training, and the other will be used for simulating batch forecasting. The training files will contain the data records before '1992-5-28' and the last part of each series will be stored in the inferencing files.\n",
        "\n",
        "Finally, we will upload both sets of data files to the Workspace's default [Datastore](https://docs.microsoft.compython/api/azureml-core/azureml.core.datastore(class))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.helper import split_data\n",
        "import pandas as pd\n",
        "\n",
        "timestamp_column = 'WeekStarting'\n",
        "split_date = '1991-05-28'\n",
        "target_path = \"data\"\n",
        "\n",
        "train_path, inference_path = split_data(target_path, timestamp_column, split_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.0 Upload data to Datastore in AML Workspace\n",
        "\n",
        "In the [setup notebook](00_Setup_AML_Workspace.ipynb) you created a [Workspace](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace.workspace). We are going to register the data in that enviroment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlw-basic-prod-202209110348 : australiaeast : This example shows how to create a basic workspace\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.ai.ml.entities import (\n",
        "    AzureBlobDatastore,\n",
        "    AzureFileDatastore,\n",
        "    AzureDataLakeGen1Datastore,\n",
        "    AzureDataLakeGen2Datastore,\n",
        ")\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "subscription_id=os.getenv(\"SUBSCRIPTION_ID\", default=\"80a3336a-33ac-4098-a7e7-64eb71d80cee\")\n",
        "resource_group=os.getenv(\"RESOURCE_GROUP\", default=\"tgrgml\")\n",
        "\n",
        "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group)\n",
        "\n",
        "for ws in ml_client.workspaces.list():\n",
        "    print(ws.name, \":\", ws.location, \":\", ws.description)\n",
        "\n",
        "workspace = \"mlw-basic-prod-202209110348\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will upload both sets of data files to your Workspace's default [Datastore](https://docs.microsoft.com/azure/machine-learning/how-to-access-data). \n",
        "A Datastore is a place where data can be stored that is then made accessible for training or forecasting. Please refer to [Datastore documentation](https://docs.microsoft.com/python/api/azureml-core/azureml.core.datastore(class)) on how to access data from Datastore.\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to default datastore\n",
        "# datastore = ws.get_default_datastore()\n",
        "\n",
        "# # Upload train data\n",
        "# ds_train_path = target_path + '_train'\n",
        "# datastore.upload(src_dir=train_path, target_path=ds_train_path, overwrite=True)\n",
        "\n",
        "# # Upload inference data\n",
        "# ds_inference_path = target_path + '_inference'\n",
        "# datastore.upload(src_dir=inference_path, target_path=ds_inference_path, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.0 Register dataset in AML Workspace\n",
        "\n",
        "The last step is creating and registering [datasets](https://docs.microsoft.com/azure/machine-learning/concept-data#datasets) in Azure Machine Learning for the train and inference sets.\n",
        "\n",
        "Using a [FileDataset](https://docs.microsoft.com/python/api/azureml-core/azureml.data.file_dataset.filedataset) is currently the best way to take advantage of the many models pattern, so we create FileDatasets in the next cell. We then [register](https://docs.microsoft.com/azure/machine-learning/how-to-create-register-datasets#register-datasets) the FileDatasets in your Workspace; this associates the train/inference sets with simple names that can be easily referred to later on when we train models and produce forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading dataset.csv\u001b[32m (< 1 MB): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 357k/357k [00:00<00:00, 9.18MB/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'train', 'description': 'Training Dataset', 'tags': {}, 'properties': {}, 'id': '/subscriptions/80a3336a-33ac-4098-a7e7-64eb71d80cee/resourceGroups/tgrgml/providers/Microsoft.MachineLearningServices/workspaces/mlw-basic-prod-202209110348/data/train/versions/1', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7faaadf43370>, 'serialize': <msrest.serialization.Serializer object at 0x7faaadf2b2b0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/80a3336a-33ac-4098-a7e7-64eb71d80cee/resourcegroups/tgrgml/workspaces/mlw-basic-prod-202209110348/datastores/workspaceblobstore/paths/LocalUpload/47ff199392829392b91ee6967b996c54/dataset.csv', 'referenced_uris': None})"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "#Upload training data\n",
        "train_data = Data(\n",
        "    path=\"./data/upload_train_data/dataset.csv\",\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Training Dataset\",\n",
        "    name=\"train\",\n",
        "    version=\"1\",\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading dataset.csv\u001b[32m (< 1 MB): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.23M/1.23M [00:00<00:00, 20.4MB/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'inference', 'description': 'Inference Dataset', 'tags': {}, 'properties': {}, 'id': '/subscriptions/80a3336a-33ac-4098-a7e7-64eb71d80cee/resourceGroups/tgrgml/providers/Microsoft.MachineLearningServices/workspaces/mlw-basic-prod-202209110348/data/inference/versions/1', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7faaadf29ba0>, 'serialize': <msrest.serialization.Serializer object at 0x7faaae0635b0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/80a3336a-33ac-4098-a7e7-64eb71d80cee/resourcegroups/tgrgml/workspaces/mlw-basic-prod-202209110348/datastores/workspaceblobstore/paths/LocalUpload/149e7bbf78efa09ced745dc85d7b5963/dataset.csv', 'referenced_uris': None})"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "#Upload inference data\n",
        "inference_data = Data(\n",
        "    path=\"./data/upload_inference_data/dataset.csv\",\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Inference Dataset\",\n",
        "    name=\"inference\",\n",
        "    version=\"1\",\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(inference_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have created your datasets, you are ready to move to one of the training notebooks to train and score the models:\n",
        "\n",
        "- Automated ML: please open [02_AutoML_Training_Pipeline.ipynb](Automated_ML/02_AutoML_Training_Pipeline/02_AutoML_Training_Pipeline.ipynb).\n",
        "- Custom Script: please open [02_CustomScript_Training_Pipeline.ipynb](Custom_Script/02_CustomScript_Training_Pipeline.ipynb)."
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "roastala"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3.10.4 ('azureml_py310_sdkv2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
